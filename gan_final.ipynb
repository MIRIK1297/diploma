{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "tf.random.set_seed(rand_seed)\n",
    "\n",
    "used_classes = ['Airliner',\n",
    "            'Sorrel',\n",
    "            'Jack-oâ€™-lantern',\n",
    "            'Panda',\n",
    "            'Anemone fish']\n",
    "\n",
    "num_classes = len(used_classes)\n",
    "num_chanels = 14\n",
    "\n",
    "data_dir = 'eeg_processed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, UpSampling1D, Conv2DTranspose, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU, Concatenate, Reshape\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(latent_dim, eeg_dim):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_eeg = Input(shape=(eeg_dim,))\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    li = Concatenate()([in_lat, in_eeg])\n",
    "    li = Dense(4*4*256)(li)\n",
    "    li = LeakyReLU(alpha=0.2)(li)\n",
    "    li = Reshape((4, 4, 256))(li)\n",
    "\n",
    "    # upsample to 8x8\n",
    "    gen = Conv2DTranspose(256, (4,4), strides=(2,2), kernel_initializer=init, padding='same')(li)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    # upsample to 16x16\n",
    "    gen = Conv2DTranspose(256, (4,4), strides=(2,2), kernel_initializer=init, padding='same')(gen)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    # upsample to 32x32\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), kernel_initializer=init, padding='same')(gen)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    # 32x32x3\n",
    "    out_layer = Conv2D(3, (3,3), kernel_initializer=init, activation='tanh', padding='same')(gen)\n",
    "    \n",
    "    model = Model([in_lat, in_eeg], out_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_discriminator(in_shape=(64, 64, 3), eeg_dim=56):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_img = Input(shape=in_shape)\n",
    "\n",
    "    # downsample to 16x16\n",
    "    conv = Conv2D(128, (4,4), strides=(2,2), kernel_initializer=init, padding='same')(in_img)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0.2)(conv)\n",
    "    \n",
    "    # downsample to 8x8\n",
    "    conv = Conv2D(256, (4,4), strides=(2,2), kernel_initializer=init, padding='same')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0.2)(conv)\n",
    "    \n",
    "    # downsample to 4x4\n",
    "    conv = Conv2D(256, (4,4), strides=(2,2), kernel_initializer=init, padding='same')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0.2)(conv)\n",
    "    \n",
    "\n",
    "    flt = Flatten()(conv)  \n",
    "    \n",
    "    in_eeg = Input(shape=(eeg_dim, ))\n",
    "    \n",
    "    dis = Concatenate()([flt, in_eeg])\n",
    "    \n",
    "    # classifier   \n",
    "    dis = Dense(512)(dis)\n",
    "    dis = ReLU()(dis)\n",
    "    out_layer = Dense(1, activation='sigmoid')(dis)\n",
    "    \n",
    "    # compile model\n",
    "    model = Model([in_img, in_eeg], out_layer)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    \n",
    "    gen_lat, gen_eeg = g_model.input\n",
    "    \n",
    "    gen_out = g_model.output\n",
    "    \n",
    "    gan_out = d_model([gen_out, gen_eeg])\n",
    "\n",
    "    # compile model\n",
    "    model = Model([gen_lat, gen_eeg], gan_out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "def crop_all(imgs, labels, target_size=(64,64), step=(2, 2)):\n",
    "    new_imgs = []\n",
    "    new_labels = []\n",
    "    for i in range(0, imgs.shape[1] - target_size[0] + 1, step[0]):\n",
    "        for j in range(0, imgs.shape[2] - target_size[1] + 1, step[1]):\n",
    "            new_imgs.append(imgs[:,i:i+target_size[0],j:j+target_size[1],:])\n",
    "            new_labels.append(labels)\n",
    "            \n",
    "    new_imgs = np.concatenate(new_imgs)\n",
    "    new_labels = np.concatenate(new_labels)\n",
    "    \n",
    "    return new_imgs, new_labels\n",
    "\n",
    "def load_real_samples(imgs_path, cropping_mode=(80, 80), crop_steps=(2,2), hor_flip=True):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for i, cl in enumerate(used_classes):\n",
    "        for img_name in [x for x in os.listdir(imgs_path + cl)  if x.endswith(\".jpg\")]:\n",
    "            if cl == 'Anemone fish' and img_name == '22.jpg':\n",
    "                    print('mdaush')\n",
    "                    continue\n",
    "            img = load_img(imgs_path + cl + '/' + img_name, target_size=cropping_mode)\n",
    "            # convert to numpy array\n",
    "            img_array = img_to_array(img)\n",
    "            imgs.append(img_array)\n",
    "            labels.append(i)\n",
    "            \n",
    "    imgs = np.asarray(imgs).astype('float32')\n",
    "    labels = np.asarray(labels)\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    imgs = (imgs - 127.5) / 127.5\n",
    "    imgs, labels = crop_all(imgs, labels, (32,32), crop_steps)\n",
    "    \n",
    "    if hor_flip:\n",
    "        #print(imgs.shape)\n",
    "        fliped = np.flip(imgs,axis=2)\n",
    "        imgs = np.concatenate([imgs, fliped])     \n",
    "        labels = np.concatenate([labels, labels])\n",
    "        #print(imgs.shape)\n",
    "        #print(fliped[0,0,:,0])\n",
    "        #print(imgs[0,0,:,0])\n",
    "        #print(imgs[imgs.shape[0]//2,0,:,0])\n",
    "        \n",
    "        #check it again\n",
    "    \n",
    "    indices = np.arange(imgs.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    imgs = imgs[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    return [imgs, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples, avg_eeg):\n",
    "    # choose random instances\n",
    "    imgs, labels = dataset\n",
    "    ix = np.random.randint(0, imgs.shape[0], n_samples)\n",
    "        \n",
    "    X, labels = imgs[ix], labels[ix]\n",
    "    X_eeg = avg_eeg[labels]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    #print(imgs[0].shape)\n",
    "    return [X, X_eeg], y\n",
    "\n",
    "\n",
    "# select real samples in order\n",
    "def generate_real_samples_ordered(dataset, n_samples, n_iter, avg_eeg):\n",
    "    # choose random instances\n",
    "    a = n_samples * n_iter\n",
    "    b = a + n_samples\n",
    "    imgs, labels = dataset\n",
    "    X, X_eeg = imgs[a:b], avg_eeg[labels[a:b]]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    #print(imgs[0].shape)\n",
    "    return [X, X_eeg], y\n",
    "\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, avg_eeg):\n",
    "    # generate points in the latent space\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    ix = np.random.randint(0, num_classes, size=n_samples)\n",
    "    eeg_input = avg_eeg[ix]\n",
    "    return [x_input, eeg_input]\n",
    "\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples, avg_eeg):\n",
    "    # generate points in latent space\n",
    "    x_input, eeg_input = generate_latent_points(latent_dim, n_samples, avg_eeg)\n",
    "    # predict outputs\n",
    "    X = g_model.predict([x_input, eeg_input])\n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return [X, eeg_input], y\n",
    "\n",
    "\n",
    "# create and save a plot of generated images\n",
    "def save_plot(examples, epoch, n=7):\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    examples = (examples + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i])\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
    "    # plot loss\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(d1_hist, label='d-real')\n",
    "    plt.plot(d2_hist, label='d-fake')\n",
    "    plt.plot(g_hist, label='gen')\n",
    "    plt.legend()\n",
    "    # plot discriminator accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(a1_hist, label='acc-real')\n",
    "    plt.plot(a2_hist, label='acc-fake')\n",
    "    plt.legend()\n",
    "    # save plot to file\n",
    "    plt.savefig('plot_line_plot_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, avg_eeg, latent_dim, n_samples=100):\n",
    "    # prepare real samples\n",
    "    [X_real, eeg_real], y_real = generate_real_samples(dataset, n_samples, avg_eeg)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate([X_real, eeg_real], y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    [x_fake, eeg_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_samples, avg_eeg)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate([x_fake, eeg_fake], y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    # save the generator model tile file\n",
    "    filename = 'generator_model_%03d.h5' % (epoch+1)\n",
    "    g_model.save(filename)\n",
    "    # save plot\n",
    "    save_plot(x_fake, epoch)\n",
    "\n",
    "\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, avg_eeg, n_epochs=100, n_batch=128):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    print('ds size={}, n_btch={}, bat_per_epo={}'.format(dataset[0].shape[0], n_batch, bat_per_epo))\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # prepare lists for storing stats each iteration\n",
    "    d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            [X_real, eeg_real], y_real = generate_real_samples(dataset, half_batch, avg_eeg)\n",
    "            # update discriminator model weights\n",
    "            d_loss1, d_acc1 = d_model.train_on_batch([X_real, eeg_real], y_real)\n",
    "            # generate 'fake' examples\n",
    "            [X_fake, eeg_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch, avg_eeg)\n",
    "            # update discriminator model weights\n",
    "            d_loss2, d_acc2 = d_model.train_on_batch([X_fake, eeg_fake], y_fake)\n",
    "            \n",
    "            # prepare points in latent space as input for the generator\n",
    "            [X_gan, eeg_gan] = generate_latent_points(latent_dim, n_batch, avg_eeg)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            \n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch([X_gan, eeg_gan], y_gan)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f, ac d1=%.3f, ac d2=%.3f' %\n",
    "                        (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss, d_acc1, d_acc2))\n",
    "            d1_hist.append(d_loss1)\n",
    "            d2_hist.append(d_loss2)\n",
    "            g_hist.append(g_loss)\n",
    "            a1_hist.append(d_acc1)\n",
    "            a2_hist.append(d_acc2)\n",
    "\n",
    "        # evaluate the model performance, sometimes\n",
    "        if (i + 1) % 10 == 0:\n",
    "            summarize_performance(i, g_model, d_model, dataset, avg_eeg, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_dim = 100\n",
    "imgs_size = 32\n",
    "imgs_folder = 'images/images_data/'\n",
    "eeg_f_dim = 56\n",
    "train_epochs = 300\n",
    "train_batch = 16\n",
    "gen_model = get_generator(lat_dim, eeg_f_dim)\n",
    "dis_model = get_discriminator((imgs_size, imgs_size, 3), eeg_f_dim)\n",
    "\n",
    "GAN_model = define_gan(gen_model, dis_model)\n",
    "\n",
    "data = load_real_samples(imgs_folder, (40,40), (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(gen_model, dis_model, GAN_model, data, lat_dim, avg_eeg_cl, train_epochs, train_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
